#!/usr/bin/env python
# coding: utf-8

""" landcover_classif.py: Land cover classification with machine learning (random forest)
Eduardo Jimenez <eduardojh@email.arizona.edu>

  Sep 16, 2022: Ported from San Juan River script.
  Jan 13, 2023: Modified for Calakmul Biosphere Reserve (local machine).
  Feb 21, 2023: Updated to use sample mask generated by stratified random sampling (moved to '01_sample_mask.py').
  May  1, 2023: RF runs with HDF5 data but needs tunning for accurate predictions.
  Jun 12, 2023: RF works and predicts okay after applying back the KISS philosophy

NOTE: run under 'rsml' conda environment (python 3.8.13, scikit-learn 1.1.2)
"""
import gc
import sys
import pickle
import csv
import h5py
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

if len(sys.argv) == 3:
    # Check if arguments were passed from terminal
    args = sys.argv[1:]
    sys.path.insert(0, args[0])
    cwd = args[1]
    print(f"  Using RS_LIB={args[0]}")
    print(f"  Using CWD={args[1]}")
else:
    import os
    import platform
    system = platform.system()
    if system == 'Windows':
        # On Windows 10
        sys.path.insert(0, 'D:/Desktop/land_cover_analysis/lib/')
        cwd = 'D:/Desktop/CALAKMUL/ROI1/'
    elif system == 'Linux' and os.path.isdir('/vipdata/2023/CALAKMUL/ROI1/'):
        # On Ubuntu Workstation
        sys.path.insert(0, '/vipdata/2023/land_cover_analysis/lib/')
        cwd = '/vipdata/2023/CALAKMUL/ROI1/'
    elif system == 'Linux' and os.path.isdir('/VIP/engr-didan02s/DATA/EDUARDO/ML/'):
        # On Alma Linux Server
        sys.path.insert(0, '/home/eduardojh/Documents/land_cover_analysis/lib/')
        cwd = '/VIP/engr-didan02s/DATA/EDUARDO/ML/'
    else:
        print('  System not yet configured!')

import rsmodule as rs

fmt = '%Y_%m_%d-%H_%M_%S'
start = datetime.now()

def read_features(filename: str, indices: dict, rows_arr: int, cols_arr: int, bands_arr: int) -> np.ndarray:
    """ Reads features from HDF5 file using its corresponding index, returns a 2D array ready for RF """
    
    x = np.empty((rows,cols,bands), dtype=np.int16)  ### TODO: CAUTION! This cast all values into integers!!!

    with h5py.File(filename, 'r') as fx:
        # Get the data from the HDF5 files
        for key in list(indices.keys()):
            dataset = indices[key]
            x[:,:,key] = fx[dataset][:]

    # Reshape x_train into a 2D-array of dimensions: (rows*cols, bands)
    x_temp = x.copy()
    x = np.empty((rows_arr*cols_arr,bands_arr), dtype=np.int16)
    i = 0
    for row in range(rows):
        for col in range(cols):
            # print(f'row={row}, col={col}: {X_temp[:,row,col]} {X_temp[:,row,col].shape}')
            # if row%500 == 0 and col%100 == 0:
            #     print(f'{i} row={row}, col={col}: {x_temp[row, col,:]} {x_temp[row, col,:].shape}')
            # Place all bands from a pixel into a row
            x[i,:] = x_temp[row, col,:]
            i += 1
    del x_temp
    return x


def land_cover_conf_table(fn_table, n_classes, **kwargs):
    """ Plots a land cover confussion table """
    _normalize = kwargs.get('normalize', False)
    _title = kwargs.get('title', '')
    _savefig = kwargs.get('savefig', '')
    _dpi = kwargs.get('dpi', 300)

    values = np.array(pd.read_csv(fn_table, header=None))
    if _normalize:
        values = (values - np.min(values)) / (np.max(values) - np.min(values))

    land_cover = [x for x in range(0, n_classes)]

    fig, ax = plt.subplots(figsize=(12,12))
    im = ax.imshow(values)

    # Show all ticks and label them with the respective list entries
    ax.set_xticks(np.arange(len(land_cover)), labels=land_cover)
    ax.set_yticks(np.arange(len(land_cover)), labels=land_cover)
    ax.grid(False)

    # Loop over data dimensions and create text annotations.
    for i in range(len(land_cover)):
        for j in range(len(land_cover)):
            if _normalize:
                text = ax.text(j, i, f'{values[i, j]:0.2f}', ha="center", va="center", color="w", fontsize='x-small')
            else:
                text = ax.text(j, i, f'{values[i, j]:0.0f}', ha="center", va="center", color="w", fontsize='x-small')
            
    if _title != '':
        ax.set_title(_title)
    if _savefig != '':
        plt.savefig(_savefig, bbox_inches='tight', dpi=_dpi)
    else:
        plt.show()
    plt.close()

# fn_landcover = cwd + 'data/inegi_2018//usv250s7cw_ROI1_LC_KEY.tif'        # Land cover raster
fn_landcover = cwd + 'data/inegi_2018/land_cover_ROI1.tif'      # Groups of land cover classes w/ancillary
fn_features = cwd + 'features/season/Calakmul_Features_season.h5'
fn_labels = cwd + 'features/Calakmul_Labels.h5'
fn_feat_indices = cwd + 'features/season/feature_indices_season.csv'
fn_parameters = cwd + 'features/season/dataset_parameters_season.csv'
# fn_colormap = cwd + 'parameters/qgis_cmap_landcover_CBR_viri.clr'  # not grouped
fn_colormap = cwd + 'parameters/qgis_cmap_landcover_CBR_viri_08grp.clr'

# File names to save results and reports
save_train_plot = cwd + f'results/{datetime.strftime(start, fmt)}_rf_training_plot.png'
save_train_stats = cwd + f'results/{datetime.strftime(start, fmt)}_rf_training_stats.csv'
save_conf_tbl = cwd + f'results/{datetime.strftime(start, fmt)}_rf_confussion_table.csv'
save_crosstab_train = cwd + f'results/{datetime.strftime(start, fmt)}_rf_crosstab_train.csv'
save_crosstab = cwd + f'results/{datetime.strftime(start, fmt)}_rf_crosstab.csv'
save_model = cwd + f'results/{datetime.strftime(start, fmt)}_rf_model.pkl'
save_report = cwd + f'results/{datetime.strftime(start, fmt)}_rf_classif_report.txt'
save_preds_raster = cwd + f'results/{datetime.strftime(start, fmt)}_rf_predictions.tif'
save_preds_fig = cwd + f'results/{datetime.strftime(start, fmt)}_rf_predictions.png'
save_params = cwd + f'results/{datetime.strftime(start, fmt)}_rf_parameters.csv'
save_importance = cwd + f'results/{datetime.strftime(start, fmt)}_rf_feat_importance.csv'

# Read the parameters saved from previous script to ensure matching
parameters = rs.read_params(fn_parameters)
# print(parameters)
rows, cols = int(parameters['ROWS']), int(parameters['COLUMNS'])
n_classes = int(parameters['NUM_CLASSES'])
bands = int(parameters['LAYERS'])

print('')
# Read the feature indices
feat_index = {}
with open(fn_feat_indices, 'r',) as csv_file:
    reader = csv.reader(csv_file, delimiter=',')
    for row in reader:
        if len(row) == 0:
            continue
        feat_index[int(row[0])] = row[1]

# #### ... OR use a list of selected features instead of all
# sel_feat_index = {}
# feature = 0
# with open(cwd + 'data_exploration/feat_anal/variables.txt', 'r') as f:
#     content = f.readlines()
# for i, line in enumerate(content):
#     line = line.strip()
#     if line != "":
#         sel_feat_index[int(feature)] = line
#         feature += 1
# # Make sure the selected features exis in the dataset
# checks = 0
# for key in sel_feat_index.keys():
#     if feat_index.get(key) is not None:
#         checks += 1
#         print(f"{key:>2}: {sel_feat_index[key]:<15} is {feat_index[key]:<15}")
# assert checks == len(sel_feat_index), f"Selected features not in data set. Only {checks}) out of {len(sel_feat_index)} exist."
# # All features in dataset, adjust dimensions
# bands = len(sel_feat_index)
# print(f"Selected {len(sel_feat_index)} out of {len(feat_index)}.")
# #### end of selected feaures, comment out this block to use all features

print(f"Running RF with {len(feat_index)} features.")
# for key in feat_index.keys():
#     print(f"{key:>2}: {feat_index[key]}")

x_train = np.empty((rows,cols,bands), dtype=np.int16)
y = np.empty((rows,cols), dtype=np.uint8)
train_mask = np.empty((rows,cols), dtype=np.uint8)
nan_mask = np.empty((rows,cols), dtype=np.uint8)

### Read the labels and features
print("Reading features and labels...")
with h5py.File(fn_labels, 'r') as fy:
    y = fy['all'][:]
    train_mask = fy['train_mask'][:]
    nan_mask = fy['no_data_mask'][:]

train_mask = train_mask.flatten()
nan_mask = nan_mask.flatten()

X = read_features(fn_features, feat_index, rows, cols, bands)
y = y.flatten()  # flatten by appending rows, each value will correspod to a row in X

print("Creating training and testing datasets...")
x_train = X[train_mask > 0]
y_train = y[train_mask > 0]

# Create a TESTING MASK: Select on the valid region only (discard NoData pixels)
test_mask = np.logical_and(train_mask == 0, nan_mask == 1)
x_test = X[test_mask]
y_test = y[test_mask]

print(f'  --x_train shape={x_train.shape}')
print(f'  --y_train shape={y_train.shape}')
print(f'  --x_test shape={x_test.shape}')
print(f'  --y_test shape={y_test.shape}')
print(f'  --X shape={X.shape}')
print(f'  --y shape={y.shape}')

tr_lbl, tr_fq = np.unique(train_mask, return_counts=True)
df_mask = pd.DataFrame({'TrainVal': tr_lbl, 'TrainFq': tr_fq})
df_mask.loc['Total'] = df_mask.sum(numeric_only=True, axis=0)
print(df_mask)

# Check labels between train and test are the same
tr_lbl, tr_fq = np.unique(y_train, return_counts=True)
df = pd.DataFrame({'TrainLbl': tr_lbl, 'TrainFreq': tr_fq})
df.loc['Total'] = df.sum(numeric_only=True, axis=0)
print(df)


### TRAIN THE RANDOM FOREST
print(f'  {datetime.strftime(datetime.now(), fmt)}: starting Random Forest training')
print('  Creating the model')
start_train = datetime.now()

rf_trees = 250
rf_depth = None
rf_jobs = 64
# class_weight = {class_label: weight}
rf_weight = None

rf = RandomForestClassifier(n_estimators=rf_trees,
                            oob_score=True,
                            max_depth=rf_depth,
                            n_jobs=rf_jobs,
                            class_weight=rf_weight,
                            verbose=1)

print(f'  {datetime.strftime(datetime.now(), fmt)}: fitting the model...')
rf = rf.fit(x_train, y_train)

# Save trained model
print("Saving trained model...")
with open(save_model, 'wb') as f:
    pickle.dump(rf, f)

print(f'  --OOB prediction of accuracy: {rf.oob_score_ * 100:0.2f}%')

feat_n = []
feat_list = []
feat_imp = []
for b, imp in zip(feat_index.keys(), rf.feature_importances_):
    # print(f'  --{feat_index[b]:>15}: {imp:>0.6f}')
    feat_n.append(b)
    feat_list.append(feat_index[b])
    feat_imp.append(imp)

feat_importance = pd.DataFrame({'Feature': feat_list, 'Importance': feat_imp})
feat_importance.sort_values(by='Importance', ascending=False, inplace=True)
print("Feature importance: ")
print(feat_importance.to_string())
feat_importance.to_csv(save_importance)

end_train = datetime.now()
training_time = end_train - start_train
print(f'  {datetime.strftime(end_train, fmt)}: training finished in {training_time}.')

# Predict on the rest of the image, using the fitted Random Forest classifier
start_pred = datetime.now()
print(f'  {datetime.strftime(start_pred, fmt)}: making predictions')

y_pred_train = rf.predict(x_train)

# A crosstabulation to see class confusion for TRAINING
df_tr = pd.DataFrame({'truth': y_train, 'predict': y_pred_train})
crosstab_tr = pd.crosstab(df_tr['truth'], df_tr['predict'], margins=True)
crosstab_tr.to_csv(save_crosstab_train)

y_pred_test = rf.predict(x_test)

# A crosstabulation to see class confusion for TESTING (MASKED)
df_ts = pd.DataFrame({'truth': y_test, 'predict': y_pred_test})
crosstab_ts = pd.crosstab(df_ts['truth'], df_ts['predict'], margins=True)
crosstab_ts.to_csv(save_crosstab[:-4] + '_test_mask.csv')

y_pred = rf.predict(X)

# A crosstabulation to see class confusion for TESTING (COMPLETE MAP)
df = pd.DataFrame({'truth': y, 'predict': y_pred})
crosstab = pd.crosstab(df['truth'], df['predict'], margins=True)
crosstab.to_csv(save_crosstab)

print(f'  --y_pred_train shape:', y_pred_train.shape)
print(f'  --y_pred_test shape:', y_pred_test.shape)
print(f'  --y_pred shape:', y_pred.shape)

accuracy = accuracy_score(y_test, y_pred_test)
print(f'  --Accuracy score (testing dataset): {accuracy}')

cm = confusion_matrix(y_test, y_pred_test)
# print('Confusion matrix:')
# print(type(cm))
# print(cm.shape)
with open(save_conf_tbl, 'w') as csv_file:
    writer = csv.writer(csv_file, delimiter=',')
    for single_row in cm:
        writer.writerow(single_row)
        # print(single_row)

report = classification_report(y_test, y_pred_test, )
print('  Classification report')
print(report)
with open(save_report, 'w') as f:
    f.write(report)

end_pred = datetime.now()
pred_time = end_pred - start_pred
print(f'  {datetime.strftime(datetime.now(), fmt)}: prediction finished in {pred_time}')

# Reshape the classification map into a 2D array again to show as a map
y_pred = y_pred.reshape((rows,cols))

print(f'  --y_pred (re)shape:', y_pred.shape)

print(f"  --Pred train: {np.unique(y_pred_train)}")
print(f"  --Pred test: {np.unique(y_pred_test)}")
print(f"  --Pred (all): {np.unique(y_pred)}")

# Plot the land cover map of the predictions for y and the whole area
rs.plot_array_clr(y_pred, fn_colormap, savefig=save_preds_fig, zero=True)  # zero=True, zeros removed with mask?

# Save GeoTIFF of the predicted land cover classes
epsg_proj = int(parameters['EPSG'])
txt = parameters[' GEOTRANSFORM'].replace('(', '').replace(')', '')
gt = [float(x) for x in txt.split(',')]

rs.create_raster(save_preds_raster, y_pred, epsg_proj, gt)

with open(save_params, 'w') as csv_file:
    writer = csv.writer(csv_file, delimiter=',')
    writer.writerow(['Parameter', 'Value'])
    writer.writerow(['Start', start])
    writer.writerow(['CWD', cwd])
    writer.writerow(['Format', fmt])
    writer.writerow(['x_train shape', f'{x_train.shape}'])
    writer.writerow(['y_train shape', f'{y_train.shape}'])
    writer.writerow(['x_test shape', f'{X.shape}'])
    writer.writerow(['y_test shape', f'{y.shape}'])
    writer.writerow(['MODEL:', 'RandomForestClassifier'])
    writer.writerow([' Estimators', rf_trees])
    writer.writerow([' Max depth', rf_depth])
    writer.writerow([' Jobs', rf_jobs])
    writer.writerow([' Class weight:', rf_weight])
    writer.writerow([' OOB prediction of accuracy', f'{rf.oob_score_}' ])
    writer.writerow([' Accuracy score', f'{accuracy}' ])
    writer.writerow([' Start training', f'{start_train}'])
    writer.writerow([' End training', f'{end_train}'])
    writer.writerow([' Training time', f'{training_time}'])
    writer.writerow([' Start testing (prediction)', start_pred])
    writer.writerow([' End testing (prediction)', end_pred])
    writer.writerow([' Testing time (prediction)', pred_time])

# Plot the confusion table
land_cover_conf_table(save_conf_tbl, len(np.unique(y_pred_test)), savefig=save_conf_tbl[:-4] + '.png', normalize=False)

# Free memory
del df_tr
del df_ts
del df
del X
del y
del x_train
del y_train
del x_test
del y_test
del y_pred_train
del y_pred_test
del y_pred
del train_mask
del nan_mask

gc.collect

print(f'  {datetime.strftime(datetime.now(), fmt)}: finished in {datetime.now() - start}')
print('  Done ;-)')

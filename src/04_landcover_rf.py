#!/usr/bin/env python
# coding: utf-8

""" landcover_classif.py: Land cover classification with machine learning (random forest)
Eduardo Jimenez <eduardojh@email.arizona.edu>

  Sep 16, 2022: Ported from San Juan River script.
  Jan 13, 2023: Modified for Calakmul Biosphere Reserve (local machine).
  Feb 21, 2023: Updated to use sample mask generated by stratified random sampling.

NOTE: run under 'rsml' conda environment (python 3.8.13, scikit-learn 1.1.2)
"""
import sys
import platform
import pickle
import csv
import h5py
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime

from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification
from skimage import data, color, io, img_as_float
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# adding the directory with modules
system = platform.system()
if system == 'Windows':
    # On Windows laptop
    sys.path.insert(0, 'D:/Desktop/land_cover_analysis/lib/')
    cwd = 'D:/Desktop/CALAKMUL/ROI1/'
elif system == 'Linux':
    # On Ubuntu machine
    sys.path.insert(0, '/vipdata/2023/land_cover_analysis/lib/')
    cwd = '/vipdata/2023/CALAKMUL/ROI1/'
else:
    print('System not yet configured!')

import rsmodule as rs

fmt = '%Y_%m_%d-%H_%M_%S'
start = datetime.now()

# ### 1. CONFIGURE
# # Paths and file names for the current ROI
# # Projection to create raster. SJR: 32612=WGS 84 / UTM zone 12N; CBR: 32616=WGS 84 / UTM zone 16N
# # epsg_proj = 32612 
# epsg_proj = 32616

# fn_landcover = cwd + 'training/usv250s7cw_ROI1_LC_KEY.tif'        # Land cover raster
# fn_train_mask = cwd + 'training/usv250s7cw_ROI1_train_mask.tif'
# fn_train_labels = cwd + 'training/usv250s7cw_ROI1_train_labels.tif'
# fn_nodata_mask = cwd + 'MONTHLY_NDVI/MONTHLY.NDVI.08.AUG.MIN.tif'   # Landsat 'NoData' filter, any file would work
# fn_phenology = cwd + '03_PHENOLOGY/LANDSAT08.PHEN.NDVI_S1.hdf'  # Phenology files
# fn_phenology2 = cwd + '03_PHENOLOGY/LANDSAT08.PHEN.NDVI_S2.hdf'

fn_features = cwd + 'Calakmul_Features.h5'
fn_train_feat = cwd + 'Calakmul_Training_Features.h5'
fn_test_feat = cwd + 'Calakmul_Testing_Features.h5'
fn_labels = cwd + 'Calakmul_Labels.h5'
fn_feat_indices = cwd + 'feature_indices.csv'
fn_parameters = cwd + 'dataset_parameters.csv'

# fn_features_split = cwd + 'Calakmul_Features_img.h5'
# fn_train_feat_split = cwd + 'Calakmul_Training_Features_img.h5'
# fn_test_feat_split = cwd + 'Calakmul_Testing_Features_img.h5'
# fn_labels_split = cwd + 'Calakmul_Labels_img.h5'

# File names to save results and reports
save_train_plot = cwd + f'results/{datetime.strftime(start, fmt)}_rf_training_plot.png'
save_train_stats = cwd + f'results/{datetime.strftime(start, fmt)}_rf_training_stats.csv'
save_conf_tbl = cwd + f'results/{datetime.strftime(start, fmt)}_rf_confussion_table.csv'
save_model = cwd + f'results/{datetime.strftime(start, fmt)}_rf_model.pkl'
save_report = cwd + f'results/{datetime.strftime(start, fmt)}_rf_classif_report.txt'
save_preds_raster = cwd + f'results/{datetime.strftime(start, fmt)}_rf_predictions.tif'
save_preds_fig = cwd + f'results/{datetime.strftime(start, fmt)}_rf_predictions.png'
save_params = cwd + f'results/{datetime.strftime(start, fmt)}_rf_parameters.csv'

# Read the parameters saved from previous script to ensure matching
parameters = rs.read_params(fn_parameters)
# print(parameters)
rows, cols = int(parameters['ROWS']), int(parameters['COLUMNS'])
row_pixels, col_pixels = int(parameters['IMG_ROWS']), int(parameters['IMG_COLUMNS'])
n_classes = int(parameters['NUM_CLASSES'])
bands = int(parameters['LAYERS'])
img_x_row = int(parameters['IMG_PER_ROW'])
img_x_col = int(parameters['IMG_PER_COL'])

# Read the feature indices
feat_index = {}
with open(fn_feat_indices, 'r',) as csv_file:
    reader = csv.reader(csv_file, delimiter=',')
    for row in reader:
        if len(row) == 0:
            continue
        feat_index[int(row[0])] = row[1]
print(feat_index)

X_train = np.empty((rows,cols,bands), dtype=np.int16)
Y_train = np.empty((rows,cols), dtype=np.uint8)
# X_train[:] = np.nan
# Y_train[:] = np.nan

# Read the labels and features
with h5py.File(fn_labels, 'r') as fy:
    Y_train = fy['training'][:]

with h5py.File(fn_train_feat, 'r') as fx:
    # Get the data from the HDF5 files
    for key in list(feat_index.keys()):
        dataset = feat_index[key]
        print(f'{key} {dataset}')
        X_train[:,:,key] = fx[dataset][:]

print(f'X_train shape={X_train.shape}')
print(f'Y_train shape={Y_train.shape}')

X_temp = X_train.copy()
X_train = np.empty((rows*cols,bands), dtype=np.int16)
# print(X_temp[0,0,:], X_temp[0,0,:].shape)
# print(X_temp[rows-1,cols-1,:], X_temp[0,0,:].shape)
i = 0
for row in range(rows):
    for col in range(cols):
        # print(f'row={row}, col={col}: {X_temp[:,row,col]} {X_temp[:,row,col].shape}')
        if row%500 == 0 and col%100 == 0:
            print(f'{i} row={row}, col={col}: {X_temp[row, col,:]} {X_temp[row, col,:].shape}')
        X_train[i,:] = X_temp[row, col,:]
        i += 1
Y_train = Y_train.flatten()

print(f'X_train shape={X_train.shape}')
print(f'Y_train shape={Y_train.shape}')

### TRAIN THE RANDOM FOREST
print(f'Starting training of Random Forests...')

# Random forest
print('Creating the model')
start_train = datetime.now()

# rf_estimators = 100
# rf_max_depth = 6
# rf_n_jobs = 14

rf_estimators = 100
rf_max_depth = 10
rf_n_jobs = 1

rf = RandomForestClassifier(n_estimators=rf_estimators, oob_score=True, max_depth=rf_max_depth, n_jobs=rf_n_jobs)

print('Fitting the model')
rf = rf.fit(X_train, Y_train)

# # Save trained model
# with open(save_model, 'wb') as f:
#     pickle.dump(rf, f)

print(f'OOB prediction of accuracy: {rf.oob_score_ * 100:0.2f}%')

#     # # A crosstabulation to see class confusion for TRAINING
#     # df = pd.DataFrame()
#     # df['truth_train'] = y_train
#     # df['predict_train'] = rf.predict(X_train)
#     # confusion_table = pd.crosstab(df['truth_train'], df['predict_train'], margins=True)
#     # confusion_table.to_csv(save_conf_tbl)

# # end_train = datetime.now()
# # training_time = end_train - start_train
# # print(f'Training finished in {training_time}')

# # # Predict on the rest of the image, using the fitted Random Forest classifier
# # print('Creating predictions for the rest of the image')
# # start_pred = datetime.now()
# # y_pred = rf.predict(X_test)
# # print(f'y_pred shape:', y_pred.shape)

# # print(f'Accuracy score: {accuracy_score(y_test, y_pred)}')

# # cm = confusion_matrix(y_test, y_pred)
# # print('Confusion matrix:')
# # # print(type(cm))
# # # print(cm.shape)
# # with open(save_conf_tbl, 'w') as csv_file:
# #     writer = csv.writer(csv_file, delimiter=',')
# #     for single_row in cm:
# #         writer.writerow(single_row)
# #         print(single_row)

# # report = classification_report(y_test, y_pred, )
# # print('Classification report')
# # print(classification_report(y_test, y_pred, ))
# # with open(save_report, 'w') as f:
# #     f.write(report)

# # # Reshape the classification map into a 2D array again to show as a map
# # y_pred = y_pred.reshape(bands_array[:, :, 0].shape)
# # print(f'y_pred (re)shape:', y_pred.shape)

# # # Save GeoTIFF of the predicted land cover classes
# # rs.create_raster(save_preds_raster, y_pred, epsg_proj, lc_gt)
 
# # end_pred = datetime.now()
# # pred_time =  end_pred - start_pred
# # print(f'Prediction finished in {pred_time}')

# # print('Plotting predictions')
# # plt.figure(figsize=(12,12))
# # plt.imshow(y_pred, cmap='viridis')
# # plt.colorbar()
# # plt.savefig(save_preds_fig, bbox_inches='tight', dpi=300)
# # plt.close()

# # print('Finishing...')

# # with open(save_params, 'w') as csv_file:
# #     writer = csv.writer(csv_file, delimiter=',')
# #     writer.writerow(['Parameter', 'Value'])
# #     writer.writerow(['Start', start])
# #     writer.writerow(['CWD', cwd])
# #     writer.writerow(['Format', fmt])
# #     writer.writerow(['Train mask raster', fn_train_mask])
# #     writer.writerow([' Metadata', f'{metadata}'])
# #     writer.writerow([' NoData', f'{nodata}'])
# #     writer.writerow([' Columns', f'{train_mask.shape[1]}'])
# #     writer.writerow([' Rows', f'{train_mask.shape[0]}'])
# #     writer.writerow([' Geotransform', f'{geotransform}'])
# #     writer.writerow([' Projection', f'{projection}'])
# #     writer.writerow(['Land cover raster', fn_landcover])
# #     writer.writerow([' Metadata', f'{lc_md}'])
# #     writer.writerow([' NoData', f'{lc_nd}'])
# #     writer.writerow([' Columns', f'{lc_arr.shape[1]}'])
# #     writer.writerow([' Rows', f'{lc_arr.shape[0]}'])
# #     writer.writerow([' Geotransform', f'{lc_gt}'])
# #     writer.writerow([' Projection', f'{lc_proj}'])
# #     writer.writerow(['Mask raster', fn_nodata_mask])
# #     writer.writerow(['Unique classes', f'{len(train_classes)}'])
# #     writer.writerow(['Training stats file', save_train_stats])
# #     writer.writerow(['Training pixels', f'{n_train}'])
# #     writer.writerow(['Total pixels', f'{n_total}'])
# #     writer.writerow(['Training percent', f'{n_train/n_total*100:>6.2f}'])
# #     writer.writerow(['Features (spectral bands)', ';'.join([x for x in bands])])
# #     writer.writerow(['Features (months)', ';'.join([x for x in months])])
# #     writer.writerow(['Features (variables)', ';'.join([x for x in vars])])
# #     writer.writerow(['Features (phenology)', ';'.join([x for x in phen])])
# #     writer.writerow(['Features (phenology2)', ';'.join([x for x in phen2])])
# #     writer.writerow(['Total features', lyrs])
# #     writer.writerow(['Bands array shape', f'{bands_array.shape}'])
# #     writer.writerow(['Phenology file', fn_phenology])
# #     writer.writerow(['Phenology 2 file', fn_phenology2])
# #     writer.writerow(['X_train shape', f'{X_train.shape}'])
# #     writer.writerow(['y_train shape', f'{y_train.shape}'])
# #     writer.writerow(['Filter shape', f'{filter.shape}'])
# #     writer.writerow(['MODEL:', 'RandomForestClassifier'])
# #     writer.writerow([' Estimators', rf_estimators])
# #     writer.writerow([' Max depth', rf_max_depth])
# #     writer.writerow([' Jobs', rf_n_jobs])
# #     writer.writerow([' OOB prediction of accuracy', f'{rf.oob_score_}' ])
# #     writer.writerow([' Start training', f'{start_train}'])
# #     writer.writerow([' End training', f'{end_train}'])
# #     writer.writerow([' Training time', f'{training_time}'])
# #     writer.writerow([' Start testing (prediction)', start_pred])
# #     writer.writerow([' End testing (prediction)', end_pred])
# #     writer.writerow([' Testing time (prediction)', pred_time])

# print('Done ;-)')
